{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperimen Prediksi _Income_ - Tugas Besar 2A IF3170 AI\n",
    "\n",
    "**Kelompok 23 - Saturnus**\n",
    "- 13515001 (K-01) - Jonathan Christopher\n",
    "- 13515008 (K-02) - Kanisius Kenneth Halim\n",
    "- 13515052 (K-01) - Kevin Jonathan\n",
    "- 13515064 (K-01) - Tasya\n",
    "- 13515065 (K-02) - Felix Limanta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "training_data = np.array(pandas.read_csv('./data/CensusIncome.data.txt', header=None))\n",
    "test_data = np.array(pandas.read_csv('./data/CensusIncome.test.txt', header=None))\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "discrete_feature_indices = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "discrete_feature_domains = {\n",
    "    'workclass': ['Private',  'Self-emp-not-inc',  'Self-emp-inc',  'Federal-gov',  'Local-gov',  'State-gov',  'Without-pay',  'Never-worked'],\n",
    "    'education': ['Bachelors',  'Some-college',  '11th',  'HS-grad',  'Prof-school',  'Assoc-acdm',  'Assoc-voc',  '9th',  '7th-8th',  '12th',  'Masters',  '1st-4th',  '10th',  'Doctorate',  '5th-6th',  'Preschool'],\n",
    "    'marital-status': ['Married-civ-spouse',  'Divorced',  'Never-married',  'Separated',  'Widowed',  'Married-spouse-absent',  'Married-AF-spouse'],\n",
    "    'occupation': ['Tech-support',  'Craft-repair',  'Other-service',  'Sales',  'Exec-managerial',  'Prof-specialty',  'Handlers-cleaners',  'Machine-op-inspct',  'Adm-clerical',  'Farming-fishing',  'Transport-moving',  'Priv-house-serv',  'Protective-serv',  'Armed-Forces'],\n",
    "    'relationship': ['Wife',  'Own-child',  'Husband',  'Not-in-family',  'Other-relative',  'Unmarried'],\n",
    "    'race': ['White',  'Asian-Pac-Islander',  'Amer-Indian-Eskimo',  'Other',  'Black'],\n",
    "    'sex': ['Female',  'Male'],\n",
    "    'native-country': ['United-States',  'Cambodia',  'England',  'Puerto-Rico',  'Canada',  'Germany',  'Outlying-US(Guam-USVI-etc)',  'India',  'Japan',  'Greece',  'South',  'China',  'Cuba',  'Iran',  'Honduras',  'Philippines',  'Italy',  'Poland',  'Jamaica',  'Vietnam',  'Mexico',  'Portugal',  'Ireland',  'France',  'Dominican-Republic',  'Laos',  'Ecuador',  'Taiwan',  'Haiti',  'Columbia',  'Hungary',  'Guatemala',  'Nicaragua',  'Scotland',  'Thailand',  'Yugoslavia',  'El-Salvador',  'Trinadad&Tobago',  'Peru',  'Hong',  'Holand-Netherlands']\n",
    "}\n",
    "discrete_value_counts = [\n",
    "    len(discrete_feature_domains['workclass']),\n",
    "    len(discrete_feature_domains['education']),\n",
    "    len(discrete_feature_domains['marital-status']),\n",
    "    len(discrete_feature_domains['occupation']),\n",
    "    len(discrete_feature_domains['relationship']),\n",
    "    len(discrete_feature_domains['race']),\n",
    "    len(discrete_feature_domains['sex']),\n",
    "    len(discrete_feature_domains['native-country'])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praproses data\n",
    "\n",
    "Data terlebih dahulu harus dipraproses dengan menghapus _whitespace_ dan memisahkan data target dari data yang digunakan untuk memrediksi. Nilai yang tidak diketahui diganti dengan modus dari nilai yang diketahui.\n",
    "\n",
    "Setelah itu, data diskrit di-_encode_ dengan _one-hot encoding_, sehingga setiap kelas data pada setiap kategori menjadi sebuah kategori sendiri, yang dapat bernilai 0 atau 1 (_boolean_). Data kontinu dinormalisasi dengan rata-rata 0 dan simpangan baku 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hapus _whitespace_ dari data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [[item.strip() if isinstance(item, str) else item for item in row] for row in training_data]\n",
    "test_data = [[item.strip() if isinstance(item, str) else item for item in row] for row in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pisahkan label _feature_ dan _target_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = np.array([row[:-1] for row in training_data])\n",
    "training_targets = np.array([row[-1] for row in training_data])\n",
    "\n",
    "test_features = np.array([row[:-1] for row in test_data])\n",
    "test_targets = np.array([row[-1] for row in test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isi nilai yang tidak diketahui dengan modus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "training_features_modes = [Counter(filter(lambda x : x != '?', column)).most_common(1)[0][0] for column in training_features.transpose()]\n",
    "for r in range(0, len(training_features)):\n",
    "    for c in range(0, len(training_features[r])):\n",
    "        if training_features[r][c] == '?':\n",
    "            training_features[r][c] = training_features_modes[c]\n",
    "            \n",
    "test_features_modes = [Counter(filter(lambda x : x != '?', column)).most_common(1)[0][0] for column in test_features.transpose()]\n",
    "for r in range(0, len(test_features)):\n",
    "    for c in range(0, len(test_features[r])):\n",
    "        if test_features[r][c] == '?':\n",
    "            test_features[r][c] = test_features_modes[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ubah nama _feature_ kategorik menjadi bilangan bulat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for r in range(0, len(training_features)):\n",
    "    for c in range(0, len(training_features[r])):\n",
    "        if c in discrete_feature_indices:\n",
    "            domain = discrete_feature_domains[feature_names[c]]\n",
    "            training_features[r][c] = domain.index(training_features[r][c])\n",
    "            \n",
    "for r in range(0, len(test_features)):\n",
    "    for c in range(0, len(test_features[r])):\n",
    "        if c in discrete_feature_indices:\n",
    "            domain = discrete_feature_domains[feature_names[c]]\n",
    "            test_features[r][c] = domain.index(test_features[r][c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Encode_ _feature_ kategorik dengan _one hot encoding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "oneHotEncoder = OneHotEncoder(categorical_features=discrete_feature_indices, n_values=discrete_value_counts)\n",
    "oneHotEncoder.fit(training_features)\n",
    "\n",
    "training_features = oneHotEncoder.transform(training_features).toarray().astype(int)\n",
    "test_features = oneHotEncoder.transform(test_features).toarray().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisasi nilai _feature_ kontinu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "training_features = training_features.astype(np.float64)\n",
    "training_features = np.hsplit(training_features, [-6])\n",
    "training_features[1] = preprocessing.scale(training_features[1])\n",
    "training_features = np.concatenate(training_features, axis=1)\n",
    "\n",
    "test_features = test_features.astype(np.float64)\n",
    "test_features = np.hsplit(test_features, [-6])\n",
    "test_features[1] = preprocessing.scale(test_features[1])\n",
    "test_features = np.concatenate(test_features, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperimen pencarian algoritma pembelajaran terbaik\n",
    "\n",
    "Eksperimen dilakukan dengan melakukan _10-fold cross validation_ pada data _training_. Skema terbaik dipilih berdasarkan rata-rata nilai _cross validation_ yang tertinggi, serta rentang 95% kepercayaan yang terendah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, training_features, training_targets, cv=10)\n",
    "print(\"Kinerja rata-rata: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "scores = cross_val_score(gnb, training_features, training_targets, cv=10)\n",
    "print(\"Kinerja rata-rata: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dtr = tree.DecisionTreeClassifier()\n",
    "scores = cross_val_score(dtr, training_features, training_targets, cv=10)\n",
    "print(\"Kinerja rata-rata: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=123)\n",
    "scores = cross_val_score(clf, training_features, training_targets, cv=10)\n",
    "print(\"Kinerja rata-rata: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(solver='sgd', hidden_layer_sizes=(50, 25), max_iter=5000, random_state=123)\n",
    "scores = cross_val_score(mlp, training_features, training_targets, cv=10)\n",
    "print(\"Kinerja rata-rata: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Full-training_ algoritma terbaik\n",
    "\n",
    "Dilakukan _full-training_ pada algoritma terbaik yang diperoleh dari eksperimen sebelumnya, lalu ditunjukkan nilai akurasi dan _confusion matrix_-nya. Model hasil _full-training_ kemudian disimpan ke _file_ eksternal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lakukan _full-training_ pada algoritma terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinerja rata-rata: 0.833328 (+/- 0.011881)\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier = mlp.fit(training_features, training_targets)\n",
    "pred = mlp_classifier.predict(training_features)\n",
    "print(\"Akurasi: %f\" % accuracy_score(training_targets, pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(training_targets, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpan model hasil _training_ ke _file_ eksternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(mlp_classifier, \"mlp_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi model hasil _training_\n",
    "\n",
    "Model yang telah disimpan dibaca kembali, lalu digunakan dan dievaluasi terhadap data uji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baca model hasil _training_ dari _file_ eksternal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinerja rata-rata: 0.854642 (+/- 0.011274)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "cv_mlp = MLPClassifier(solver='sgd', hidden_layer_sizes=(8, 8), max_iter=2500, random_state=1)\n",
    "scores = cross_val_score(cv_mlp, training_features, training_targets, cv=10)\n",
    "print(\"Kinerja rata-rata: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinerja rata-rata: 0.547865 (+/- 0.029052)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "scores = cross_val_score(gnb, training_features, training_targets, cv=10)\n",
    "print(\"Kinerja rata-rata: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinerja rata-rata: 0.817666 (+/- 0.016075)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dtr = tree.DecisionTreeClassifier()\n",
    "scores = cross_val_score(dtr, training_features, training_targets, cv=10)\n",
    "print(\"Kinerja rata-rata: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = joblib.load(\"mlp_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lakukan klasifikasi untuk data uji dengan model yang telah dibaca\n",
    "\n",
    "Karena terdapat puluhan ribu data uji, hasil yang ditampilkan adalah metrik performanya, yaitu akurasi dan _confusion matrix_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mlp_classifier.predict(test_features)\n",
    "print(\"Akurasi: %f\" % accuracy_score(test_targets, pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(test_targets, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
